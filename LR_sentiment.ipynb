{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_extractor(corpus):  \n",
    "    # returns a frequency-based DTM\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=(1,1)) \n",
    "    features = vectorizer.fit_transform(corpus) # transform texts to a frequency matrix\n",
    "    return vectorizer, features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf_extractor(corpus):\n",
    "    # returns a tf-idf based DTM\n",
    "    vectorizer = TfidfVectorizer(min_df=1, \n",
    "                                 norm='l2',\n",
    "                                 ngram_range=(1,1))\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2016_filtered_review.txt', encoding='utf-8') as f:\n",
    "    docs = [doc.strip().split('\\t\\t') for doc in f]\n",
    "    docs = [(doc[1], int(doc[2])) for doc in docs if len(doc) == 3]\n",
    "    # To read the second and third column info from each row\n",
    "    texts, scores = zip(*docs)\n",
    "    # 둘을 분리해서 별도의 list 변수로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_texts = []\n",
    "filtered_labels = []\n",
    "\n",
    "for text, score in zip(texts, scores):\n",
    "    if 4 < score < 8:\n",
    "        continue\n",
    "        \n",
    "    # 평점 기준으로 문서에 label을 부여\n",
    "    # 1 ~ 4 -> 부정, 0\n",
    "    # 8 ~ 10 -> 긍정, 1\n",
    "    filtered_texts.append(text)\n",
    "    filtered_labels.append(1 if score >= 8 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To split the data into training and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(filtered_texts, filtered_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_vectorizer, train_tf_features = tf_extractor(train_texts) # TF 정보를 이용해서 벡터화 합니다.\n",
    "# input의 형태 = list of docs\n",
    "test_tf_features = tf_vectorizer.transform(test_texts)\n",
    "vocablist = [word for word, _ in sorted(tf_vectorizer.vocabulary_.items(), key=lambda x:x[1])]\n",
    "# tf_vectorizer.vocabulary_.items() returns a list of (word, frequency)\n",
    "# We sort words based on their frequencies and save the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 11760 out of 164523\n",
      "Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# tf matrix를 사용한 경우\n",
    "lr2 = LogisticRegression(C=10, penalty='l2', solver='sag') # Ridge regression\n",
    "# C = Inverse of regularization strength, 즉 C 값이 작을수록 penalty를 많이 준다는 것입니다.\n",
    "# penalty를 많이 준다는 뜻은 L1 같은 경우는 feature의 수를 그만큼 많이 줄인다는 뜻이고\n",
    "# L2인 경우는 weight 값을 더 0에 가깝게 한다는 뜻입니다.\n",
    "lr2.fit(train_tf_features, train_labels) # 학습\n",
    "pred_labels = lr2.predict(test_tf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Misclassified samples: {} out of {}'.format((pred_labels != test_labels).sum(),len(test_labels)))\n",
    "print('Accuracy: %.2f' % accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 14074 out of 164523\n",
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# tfidf matrix를 사용한 경우\n",
    "tfidf_vectorizer, train_tfidf_features = tfidf_extractor(train_texts)\n",
    "test_tfidf_features = tfidf_vectorizer.transform(test_texts)\n",
    "lr = LogisticRegression(C=0.1, penalty='l1', solver='saga') # Lasso regression\n",
    "lr.fit(train_tfidf_features, train_labels) # 학습\n",
    "pred_labels = lr.predict(test_tfidf_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Misclassified samples: {} out of {}'.format((pred_labels != test_labels).sum(),len(test_labels)))\n",
    "print('Accuracy: %.2f' % accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8402, 3.2834260607516965), (50619, 2.8758307801962313), (49991, 2.793400720353563), (50012, 2.7417887272975565), (50561, 2.731604141685505)]\n",
      "꿀잼 (3.283)\n",
      "재밌었 (2.876)\n",
      "재미있게 (2.793)\n",
      "재미있었 (2.742)\n",
      "재밌게 (2.732)\n",
      "존잼 (2.517)\n",
      "재미있네 (2.500)\n",
      "여운 (2.481)\n",
      "재밌어 (2.443)\n",
      "재밌네 (2.430)\n",
      "재미있어 (2.422)\n",
      "강추 (2.414)\n",
      "굿굿 (2.363)\n",
      "재밌고 (2.356)\n",
      "즐겁 (2.171)\n",
      "최고다 (2.169)\n",
      "지루할 (2.167)\n",
      "지루하지 (2.111)\n",
      "유쾌 (2.110)\n",
      "개꿀잼 (2.065)\n",
      "재미있 (2.053)\n",
      "재밌던 (2.028)\n",
      "테러 (1.980)\n",
      "심장 (1.956)\n",
      "졸잼 (1.954)\n",
      "재밌 (1.940)\n",
      "재밋어 (1.938)\n",
      "수작 (1.937)\n",
      "재미있고 (1.934)\n",
      "울었 (1.925)\n",
      "사랑해 (1.918)\n",
      "최고 (1.875)\n",
      "흥미진진 (1.867)\n",
      "감사합 (1.858)\n",
      "재밋 (1.855)\n",
      "빠져 (1.851)\n",
      "대박 (1.845)\n",
      "낮아 (1.827)\n",
      "감사 (1.791)\n",
      "감탄 (1.772)\n",
      "충분히 (1.763)\n",
      "탄탄 (1.762)\n",
      "가슴 (1.755)\n",
      "재밋음 (1.751)\n",
      "멋지 (1.745)\n",
      "만점 (1.721)\n",
      "전문가 (1.685)\n",
      "재미나 (1.665)\n",
      "웃다 (1.656)\n",
      "다만 (1.649)\n",
      "없고 (-1.821)\n",
      "미화 (-1.837)\n",
      "알바 (-1.847)\n",
      "댓글알바 (-1.862)\n",
      "표절 (-1.866)\n",
      "짜증 (-1.869)\n",
      "높아 (-1.885)\n",
      "신파극 (-1.887)\n",
      "왜곡 (-1.913)\n",
      "삼류 (-1.919)\n",
      "디워 (-1.919)\n",
      "자다 (-1.921)\n",
      "별로 (-1.939)\n",
      "억지 (-1.940)\n",
      "아까웠 (-1.959)\n",
      "팔이 (-1.983)\n",
      "망쳐 (-2.010)\n",
      "제로 (-2.029)\n",
      "하품 (-2.045)\n",
      "아까운 (-2.053)\n",
      "재미없 (-2.071)\n",
      "거품 (-2.105)\n",
      "졸다 (-2.110)\n",
      "실망 (-2.146)\n",
      "클레멘타인 (-2.168)\n",
      "불륜 (-2.175)\n",
      "별루 (-2.181)\n",
      "실망했 (-2.183)\n",
      "역사왜곡 (-2.215)\n",
      "졸려 (-2.218)\n",
      "지루해 (-2.232)\n",
      "망작 (-2.247)\n",
      "불면증 (-2.273)\n",
      "그닥 (-2.274)\n",
      "이하 (-2.345)\n",
      "엉망 (-2.378)\n",
      "낭비 (-2.378)\n",
      "지루하고 (-2.422)\n",
      "나가고 (-2.422)\n",
      "쓰레기 (-2.459)\n",
      "비추 (-2.487)\n",
      "졸았 (-2.556)\n",
      "아까 (-2.599)\n",
      "지루했 (-2.651)\n",
      "지루해서 (-2.761)\n",
      "졸작 (-2.774)\n",
      "아까워 (-2.850)\n",
      "차라리 (-2.856)\n",
      "노잼 (-3.437)\n",
      "최악 (-4.243)\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients of the model \n",
    "coefficients = lr.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# 학습에 사용된 각 단어마다의 coefficient (즉 weight) 값이 존재\n",
    "# coefficient값이 큰 순으로 정렬 'reverse=True'\n",
    "\n",
    "print(sorted_coefficients[:5])\n",
    "# print top 50 positive words\n",
    "for word, coef in sorted_coefficients[:50]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))\n",
    "# print top 50 negative words\n",
    "for word, coef in sorted_coefficients[-50:]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
